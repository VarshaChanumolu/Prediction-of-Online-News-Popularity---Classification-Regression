# -*- coding: utf-8 -*-
"""Project Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15KHgmU_MHIkgia0bd4i9CGq4fr5MpVN_

### Data
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
pd.set_option('display.max_columns', None)

Onews = pd.read_csv('OnlineNewsPopularity.csv')
Onews.head()

Onews.columns = Onews.columns.str.replace(' ', '')

Onews['timedelta'].value_counts()

Onews = Onews.drop(['url'], axis = 1)

Onews.head()

Onews.describe(include = "all").T

Onews['n_tokens_content'].value_counts()

"""n_tokens_content ----->>> the tokens present in the article ... cannot be 0"""

Onews = Onews[Onews['n_tokens_content'] != 0]
Onews.shape

Onews.describe(include = "all").T

Onews = Onews[Onews['kw_min_min'] != -1]
Onews.shape

Onews.describe(include = "all").T

OnewsN = Onews.drop(['self_reference_min_shares','self_reference_max_shares', 'self_reference_avg_sharess'], axis = 1)
OnewsN.shape

OnewsN = OnewsN.drop(['is_weekend'], axis = 1)
OnewsN.shape

OnewsN.info()

def outliers(df, columns = None):
    if not columns:
        columns = df.columns
    
    for c in columns:
        Q1 = df[c].quantile(0.25)
        Q3 = df[c].quantile(0.75)
        IQR = Q3 - Q1
        floor, ceil = Q1 - 1.5*IQR, Q3 + 1.5*IQR
        
        df = df[(df[c] >= floor) & (df[c] <= ceil)]
    return df

OnewsNew = outliers(OnewsN,['shares'])

OnewsNew.head()

OnewsN.shape

OnewsNew.shape

import seaborn as sns

sns.boxplot(OnewsN['shares'])

sns.boxplot(OnewsNew['shares'])

OnewsNew1 = outliers(OnewsNew, ['shares'])

OnewsNew1.shape

sns.boxplot(OnewsNew1['shares'])

sns.distplot(OnewsNew1['shares'])

OnewsNew2 = outliers(OnewsNew1, ['shares'])

sns.boxplot(OnewsNew2['shares'])

sns.distplot(OnewsNew2['shares'])

OnewsNew2.shape, OnewsNew1.shape

OnewsNew1['shares'].mean()

OnewsNew1.describe(include = "all").T

OnewsNew1.info()

plt.figure(figsize = (50, 50))

sns.heatmap(OnewsNew2.corr(), annot = True)
plt.show()

##col = ['n_tokens_content','n_unique_tokens', 'n_non_stop_words',
 #      'n_non_stop_unique_tokens','average_token_length', 'kw_min_min',
  #     'kw_max_min','kw_avg_min','kw_min_max','kw_max_max', 'kw_avg_max',
  #     'kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares',
  #     'self_reference_max_shares','global_sentiment_polarity',
  #     'global_rate_positive_words','global_rate_negative_words',
  #     'avg_positive_polarity','min_positive_polarity','max_positive_polarity',
  #     'avg_negative_polarity','min_negative_polarity',
   #    'max_negative_polarity', 'abs_title_subjectivity',
   #    'abs_title_sentiment_polarity','data_channel_is_lifestyle','data_channel_is_tech',
   #    'data_channel_is_entertainment','data_channel_is_bus',
   #    'data_channel_is_socmed','data_channel_is_world',
  #     'weekday_is_monday','weekday_is_tuesday','weekday_is_wednesday',
   #    'weekday_is_thursday','weekday_is_friday','weekday_is_saturday',
   #    'weekday_is_sunday','is_weekend','LDA_00','LDA_01','LDA_02',
    #   'LDA_03','LDA_04'
   #   ]

col = ['n_tokens_content', 
      'n_unique_tokens',
      'kw_max_max', 'kw_max_min', 'kw_max_avg',
      'rate_positive_words', 'rate_negative_words',
      'avg_negative_polarity','avg_positive_polarity','title_subjectivity']

OnewsNew3 = OnewsNew2.drop(col, axis = 1)

OnewsNew3.info()

"""col = ['n_tokens_content','n_unique_tokens', 'n_non_stop_words',
       'n_non_stop_unique_tokens','average_token_length', 'kw_min_min',
       'kw_max_min','kw_avg_min','kw_min_max','kw_max_max', 'kw_avg_max',
       'kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares',
       'self_reference_max_shares','global_sentiment_polarity',
       'global_rate_positive_words','global_rate_negative_words',
       'avg_positive_polarity','min_positive_polarity','max_positive_polarity',
       'avg_negative_polarity','min_negative_polarity',
       'max_negative_polarity', 'abs_title_subjectivity',
       'abs_title_sentiment_polarity']
       
OnewsNew4 = OnewsNew2.drop(col, axis = 1)
"""



sns.distplot(OnewsNew3['shares'])

OnewsNew3['shares'].mean(), OnewsNew3['shares'].median(), OnewsNew3['shares'].min(), OnewsNew3['shares'].max()

OnewsNew4['popular'] = [1 if x >= 1200 else 0 for x in OnewsNew4['shares']]
OnewsNew4.head()

OnewsNew3['popular'] = [1 if x >= 1200 else 0 for x in OnewsNew3['shares']]
OnewsNew2.head()

OnewsNew3['popular'].value_counts()

OnewsNew3.describe(include = "all").T

from sklearn.model_selection import train_test_split

X = OnewsNew3.drop(['shares','popular'], axis = 1)
Y = OnewsNew3[['popular']]

X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.7, random_state = 100)

X4 = OnewsNew4.drop(['shares','popular'], axis = 1)
Y4 = OnewsNew4[['popular']]

X_train4, X_test4, y_train4, y_test4 = train_test_split(X, Y, train_size = 0.7, random_state = 100)

X_train.shape, X_test.shape# X_train4.shape

"""## Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)
y_pred = dtree.predict(X_test)

from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report

f1_score(y_test, y_pred)

print(classification_report(y_test, y_pred))

dtree.score(X_train, y_train)

dtree.score(X_test, y_test)

dtree.fit(X_train4, y_train4)
y_pred = dtree.predict(X_test4)
print(classification_report(y_test, y_pred))

from sklearn.model_selection import cross_val_score,RepeatedKFold,GridSearchCV

dtree = DecisionTreeClassifier()

cv = RepeatedKFold(n_splits = 100, n_repeats = 2)
grid = {}
grid['min_samples_leaf'] = np.arange(45,65, 5) # the number of samples to be present in the leaf
grid['max_features'] = np.arange(4, 8, 1)

search = GridSearchCV(dtree, grid, scoring = "neg_mean_absolute_error", cv = cv, n_jobs = -1)
res = search.fit(X, Y)

search.best_estimator_

dtreeBest = search.best_estimator_
dtreeBest.fit(X_train, y_train)
y_pred = dtreeBest.predict(X_test)
print(classification_report(y_test, y_pred))

"""## Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

rfclf = RandomForestClassifier(n_estimators = 40)

rfclf.fit(X_train, y_train)
y_pred = rfclf.predict(X_test)
print(classification_report(y_test, y_pred))

rfclf = RandomForestClassifier()

cv = RepeatedKFold(n_splits = 100, n_repeats = 2)
grid = {}
grid['n_estimators'] = np.arange(60, 81, 10)
#grid['min_samples_leaf'] = np.arange(40, 65, 5)

search = GridSearchCV(rfclf, grid, scoring = "neg_mean_absolute_error", cv = cv, n_jobs = -1)
res = search.fit(X, Y)

search.best_estimator_

rfclfBest = search.best_estimator_
rfclfBest.fit(X_train, y_train)
y_pred = rfclfBest.predict(X_test)
print(classification_report(y_test, y_pred))

rfclf = RandomForestClassifier(n_estimators = 110)
rfclf.fit(X_train, y_train)
y_pred = rfclf.predict(X_test)
print(classification_report(y_test, y_pred))

"""## KNN"""

from sklearn.preprocessing import MinMaxScaler

scale = MinMaxScaler()

X_train = scale.fit_transform(X_train) # fit the data and then transform it
X_test = scale.transform(X_test) # find the min and max and then later scale it

from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import confusion_matrix,plot_confusion_matrix, plot_roc_curve

knnclf = KNeighborsClassifier(n_neighbors = 31)
knnclf.fit(X_train, y_train)
y_pred = knnclf.predict(X_test)

print(classification_report(y_test, y_pred))

knnclf = KNeighborsClassifier(metric = "manhattan")

cv = RepeatedKFold(n_splits = 100, n_repeats = 2)
grid = {}
grid['n_neighbors'] = np.arange(41, 80, 11)

search = GridSearchCV(knnclf, grid, scoring = "neg_mean_absolute_error", cv = cv, n_jobs = -1)
res = search.fit(X, Y)

search.best_estimator_

knnclfBest = search.best_estimator_
knnclfBest.fit(X_train, y_train)
y_pred = knnclfBest.predict(X_test)

print(classification_report(y_test, y_pred))

knnclf = KNeighborsClassifier(metric = "manhattan", n_neighbors = 69)
knnclf.fit(X_train, y_train)
y_pred = knnclf.predict(X_test)
print(classification_report(y_test, y_pred))

plot_confusion_matrix(knnclf, X_train, y_train)

plot_roc_curve(knnclf, X_test, y_test)

plot_roc_curve(knnclf, X_train, y_train)